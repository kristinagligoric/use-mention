{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d371cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stops = set(stopwords.words('english'))\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer as CV\n",
    "import string\n",
    "exclude = set(string.punctuation)\n",
    "\n",
    "def process_labels(x):\n",
    "    t = str(x).lower().strip('\"').strip('[').strip(' ').strip('\\n').strip(' ')\n",
    "    if t=='misinformation':\n",
    "        return 1\n",
    "    elif t=='not misinformation':\n",
    "        return 0\n",
    "    elif ('not' in t) or ('mis' in t):\n",
    "        return 0\n",
    "    else:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73a997e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/fightin_words.csv')\n",
    "\n",
    "df['label_gpt3.5'] = df['label_gpt3.5'].apply(lambda x: process_labels(x))  \n",
    "df['label_gpt4'] = df['label_gpt4'].apply(lambda x: process_labels(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5a9f472",
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_sanitize(in_string):\n",
    "    '''Returns a very roughly sanitized version of the input string.'''  \n",
    "    in_string = ''.join([ch for ch in in_string if ch not in exclude])\n",
    "    in_string = in_string.lower()\n",
    "    in_string = ' '.join(in_string.split())\n",
    "    return in_string\n",
    "\n",
    "def bayes_compare_language(l1, l2, ngram = 1, prior=.01, cv = None):\n",
    "    '''\n",
    "    Arguments:\n",
    "    - l1, l2; a list of strings from each language sample\n",
    "    - ngram; an int describing up to what n gram you want to consider (1 is unigrams,\n",
    "    2 is bigrams + unigrams, etc). Ignored if a custom CountVectorizer is passed.\n",
    "    - prior; either a float describing a uniform prior, or a vector describing a prior\n",
    "    over vocabulary items. If you're using a predefined vocabulary, make sure to specify that\n",
    "    when you make your CountVectorizer object.\n",
    "    - cv; a sklearn.feature_extraction.text.CountVectorizer object, if desired.\n",
    "    Returns:\n",
    "    - A list of length |Vocab| where each entry is a (n-gram, zscore) tuple.'''\n",
    "    if cv is None and type(prior) is not float:\n",
    "        print(\"If using a non-uniform prior:\")\n",
    "        print(\"Please also pass a count vectorizer with the vocabulary parameter set.\")\n",
    "        quit()\n",
    "    l1 = [basic_sanitize(l) for l in l1]\n",
    "    l2 = [basic_sanitize(l) for l in l2]\n",
    "    if cv is None:\n",
    "        cv = CV(decode_error = 'ignore', min_df = 3, max_df = .5, stop_words = list(stops) + ['timeslive','amp','sundaytimesza','headline','cj','littlefamilyoz','benmitchellsong','africaupdates','davidfrum','africa','south','devil','god','ur','world'],\n",
    "                ngram_range=(1,ngram),\n",
    "                binary = False,\n",
    "                max_features = 15000)\n",
    "    counts_mat = cv.fit_transform(l1+l2).toarray()\n",
    "    # Now sum over languages...\n",
    "    vocab_size = len(cv.vocabulary_)\n",
    "    print(\"Vocab size is {}\".format(vocab_size))\n",
    "    if type(prior) is float:\n",
    "        priors = np.array([prior for i in range(vocab_size)])\n",
    "    else:\n",
    "        priors = prior\n",
    "    z_scores = np.empty(priors.shape[0])\n",
    "    count_matrix = np.empty([2, vocab_size], dtype=np.float32)\n",
    "    count_matrix[0, :] = np.sum(counts_mat[:len(l1), :], axis = 0)\n",
    "    count_matrix[1, :] = np.sum(counts_mat[len(l1):, :], axis = 0)\n",
    "    a0 = np.sum(priors)\n",
    "    n1 = 1.*np.sum(count_matrix[0,:])\n",
    "    n2 = 1.*np.sum(count_matrix[1,:])\n",
    "    print(\"Comparing language...\")\n",
    "    for i in range(vocab_size):\n",
    "        #compute delta\n",
    "        term1 = np.log((count_matrix[0,i] + priors[i])/(n1 + a0 - count_matrix[0,i] - priors[i]))\n",
    "        term2 = np.log((count_matrix[1,i] + priors[i])/(n2 + a0 - count_matrix[1,i] - priors[i]))        \n",
    "        delta = term1 - term2\n",
    "        #compute variance on delta\n",
    "        var = 1./(count_matrix[0,i] + priors[i]) + 1./(count_matrix[1,i] + priors[i])\n",
    "        #store final score\n",
    "        z_scores[i] = delta/np.sqrt(var)\n",
    "    index_to_term = {v:k for k,v in cv.vocabulary_.items()}\n",
    "    sorted_indices = np.argsort(z_scores)\n",
    "    return_list = []\n",
    "    for i in sorted_indices:\n",
    "        return_list.append((index_to_term[i], z_scores[i]))\n",
    "    return return_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df6907b",
   "metadata": {},
   "source": [
    "### gpt4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf2a8778",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pos = (df.loc[((df['label_gpt4']==1)) & (df['type']=='disapproving')]).reset_index()['text']\n",
    "df_neg = (df.loc[((df['label_gpt4']==0)) & (df['type']=='disapproving')]).reset_index()['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f5f7905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size is 959\n",
      "Comparing language...\n"
     ]
    }
   ],
   "source": [
    "l1 = list(df_pos)\n",
    "l2 = list(df_neg)\n",
    "\n",
    "res = bayes_compare_language((l1), (l2),  ngram = 1, prior= 0.01,\n",
    "                             cv = None)\n",
    "res = pd.DataFrame(res)\n",
    "res['word'] = res[0]\n",
    "res['z-score'] = res[1]\n",
    "\n",
    "#keep only significant (95% CI)\n",
    "\n",
    "#res = res.loc[(res['z-score'] < -1.97) |  (res['z-score'] > 1.97)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0620c5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "please (-3.67), vaccine (-3.61), therapy (-3.53), gene (-3.32), misinformation (-3.23), stop (-2.82), mrna (-2.52), dna (-2.43), uses (-2.41), wrong (-2.27), change (-2.10), correct (-2.03), safe (-2.01), cdc (-1.99), well (-1.93)\n"
     ]
    }
   ],
   "source": [
    "words = res[['word', 'z-score']].loc[res['z-score'] <0].sort_values(by= 'z-score', ascending = True)['word'].values\n",
    "scores = res[['word', 'z-score']].loc[res['z-score'] <0].sort_values(by= 'z-score', ascending = True)['z-score'].values\n",
    "\n",
    "print(\", \".join(\"%s (%.2f)\"%(words[i],scores[i]) for i in range(len(words))[:15]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "235e4856",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fake (5.03), news (4.89), lying (4.27), lies (4.16), one (3.94), misleading (3.84), lie (3.76), put (3.43), thing (3.35), always (3.13), false (3.10), new (2.98), everything (2.83), anyway (2.83), country (2.83)\n"
     ]
    }
   ],
   "source": [
    "words = res[['word', 'z-score']].loc[res['z-score'] >0].sort_values(by= 'z-score', ascending = True)['word'].values[::-1]\n",
    "scores = res[['word', 'z-score']].loc[res['z-score'] >0].sort_values(by= 'z-score', ascending = True)['z-score'].values[::-1]\n",
    "\n",
    "print(\", \".join(\"%s (%.2f)\"%(words[i],scores[i]) for i in range(len(words))[:15]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f250ec1f",
   "metadata": {},
   "source": [
    "### gpt3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65abdc0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pos = (df.loc[((df['label_gpt3.5']==1)) & (df['type']=='disapproving')]).reset_index()['text']\n",
    "df_neg = (df.loc[((df['label_gpt3.5']==0)) & (df['type']=='disapproving')]).reset_index()['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "978c556e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size is 948\n",
      "Comparing language...\n"
     ]
    }
   ],
   "source": [
    "l1 = list(df_pos)\n",
    "l2 = list(df_neg)\n",
    "\n",
    "res = bayes_compare_language((l1), (l2),  ngram = 1, prior= 0.01,\n",
    "                             cv = None)\n",
    "res = pd.DataFrame(res)\n",
    "res['word'] = res[0]\n",
    "res['z-score'] = res[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d407bb75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mrna (-4.24), vaccine (-3.40), dna (-2.82), uses (-2.82), change (-2.77), please (-2.17), genes (-2.15), genetic (-2.12), actually (-2.09), gene (-2.06), therapy (-2.06), understand (-2.02), correct (-1.86), immunization (-1.86), nothing (-1.79)\n"
     ]
    }
   ],
   "source": [
    "words = res[['word', 'z-score']].loc[res['z-score'] <0].sort_values(by= 'z-score', ascending = True)['word'].values\n",
    "scores = res[['word', 'z-score']].loc[res['z-score'] <0].sort_values(by= 'z-score', ascending = True)['z-score'].values\n",
    "\n",
    "print(\", \".join(\"%s (%.2f)\"%(words[i],scores[i]) for i in range(len(words))[:15]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "217d53c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fake (5.39), misleading (5.08), lying (4.31), lies (4.20), media (4.09), news (4.03), another (3.60), report (3.39), journalism (3.37), blood (2.94), false (2.92), crazy (2.65), justice (2.64), remove (2.48), reporting (2.45)\n"
     ]
    }
   ],
   "source": [
    "words = res[['word', 'z-score']].loc[res['z-score'] >0].sort_values(by= 'z-score', ascending = True)['word'].values[::-1]\n",
    "scores = res[['word', 'z-score']].loc[res['z-score'] >0].sort_values(by= 'z-score', ascending = True)['z-score'].values[::-1]\n",
    "\n",
    "print(\", \".join(\"%s (%.2f)\"%(words[i],scores[i]) for i in range(len(words))[:15]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
