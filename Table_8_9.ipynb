{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4cfccba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df_m = pd.read_csv('data/mitigations_misinfo.csv')\n",
    "df_h = pd.read_csv('data/mitigations_hate.csv')\n",
    "\n",
    "df_m['cot_full_3'] = df_m['label_gpt3.5_prompt_4']\n",
    "df_m['cot_full_4'] = df_m['label_gpt4_prompt_4']\n",
    "\n",
    "df_h['cot_full_3'] = df_h['label_gpt3.5_prompt_4']\n",
    "df_h['cot_full_4'] = df_h['label_gpt4_prompt_4']\n",
    "\n",
    "cols = ['label_gpt4_prompt_1', 'label_gpt4_prompt_2','label_gpt4_prompt_3',\n",
    "        'label_gpt3.5_prompt_1', 'label_gpt3.5_prompt_2', 'label_gpt3.5_prompt_3']\n",
    "\n",
    "cot_prompts = ['label_gpt3.5_prompt_4','label_gpt4_prompt_4']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93aa216b",
   "metadata": {},
   "source": [
    "#### Process misinfo outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17c96615",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_labels(x):\n",
    "    t = str(x).lower().strip('\"').strip('[').strip(' ').strip('\\n').strip(' ')\n",
    "    if t=='misinformation':\n",
    "        return 1\n",
    "    elif t=='not misinformation':\n",
    "        return 0\n",
    "    elif ('not' in t) or ('mis' in t):\n",
    "        return 0\n",
    "    else:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd24abce",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in cols:\n",
    "    df_m[col] = df_m[col].apply(lambda x: process_labels(x))  \n",
    "df_m = df_m.dropna(subset = cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9fda7a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_cot(x):\n",
    "    x = str(x).split(':')[-1].strip('.').strip(' ')\n",
    "    negative_label = 'not misinformation'\n",
    "    if x=='misinformation':\n",
    "        return 1\n",
    "    elif x=='not misinformation' or x[-len(negative_label):] == negative_label:\n",
    "        return 0\n",
    "    elif x=='nan':\n",
    "        return np.nan\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "for cot_prompt in cot_prompts:\n",
    "    df_m[cot_prompt] = df_m[cot_prompt].apply(lambda x: process_cot(x))\n",
    "df_m = df_m.dropna(subset = cot_prompts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1547c85",
   "metadata": {},
   "source": [
    "#### Process hate outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9c64525",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_labels(x):\n",
    "    t = str(x).lower().strip('\"').strip(' ').strip(' ').strip('[').strip('(').strip('\\n').strip(' ').strip('.')\n",
    "    if t=='hateful' or t=='h' or t=='hate':\n",
    "        return 1\n",
    "    elif t=='not hateful':\n",
    "        return 0\n",
    "    elif 'not' in t:\n",
    "        return 0\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "for col in cols:\n",
    "    df_h[col] = df_h[col].apply(lambda x: process_labels(x))  \n",
    "df_h = df_h.dropna(subset = cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "961c3a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_cot(x):\n",
    "    \n",
    "    x = str(x).lower().split(':')[-1].strip('.').strip(' ')\n",
    "    negative_label = 'not hateful'\n",
    "    if x=='hateful':\n",
    "        return 1\n",
    "    elif x=='not hateful' or x[-len(negative_label):] == negative_label:\n",
    "        return 0\n",
    "    elif x=='nan':\n",
    "        return np.nan\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "for cot_prompt in cot_prompts:\n",
    "    df_h[cot_prompt] = df_h[cot_prompt].apply(lambda x: process_cot(x))\n",
    "df_h = df_h.dropna(subset = cot_prompts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6134bc0b",
   "metadata": {},
   "source": [
    "#### Analyses misinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e2e2630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "293\n",
      "58.02\n",
      "46.76\n",
      "73.04\n"
     ]
    }
   ],
   "source": [
    "list_entries = []\n",
    "df_t = df_m.loc[df_m['label_gpt3.5']==1]\n",
    "print(len(df_t))\n",
    "for col in ['label_gpt3.5_prompt_1', 'label_gpt3.5_prompt_3','label_gpt3.5_prompt_4']:\n",
    "    entry = {}\n",
    "    entry['cond'] = col\n",
    "    entry['val'] = -round((100 - df_t[col].mean()*100),2)\n",
    "    entry['model'] = 'gpt-3.5'\n",
    "    entry['task'] = 'misinfo'\n",
    "    print(round((100 - df_t[col].mean()*100),2))\n",
    "    list_entries.append(entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b1abe15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149\n",
      "48.32\n",
      "28.19\n",
      "59.06\n"
     ]
    }
   ],
   "source": [
    "df_t = df_m.loc[df_m['label_gpt4']==1]\n",
    "print(len(df_t))\n",
    "for col in ['label_gpt4_prompt_1', 'label_gpt4_prompt_3','label_gpt4_prompt_4']:\n",
    "    entry = {}\n",
    "    entry['cond'] = col\n",
    "    entry['val'] = -round((100 - df_t[col].mean()*100),2)\n",
    "    entry['model'] = 'gpt-4'\n",
    "    entry['task'] = 'misinfo'\n",
    "    print(round((100 - df_t[col].mean()*100),2))\n",
    "    list_entries.append(entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a68f01c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149\n",
      "5.276528\n",
      "7.331801\n",
      "4.179974\n"
     ]
    }
   ],
   "source": [
    "df_t = df_m.loc[df_m['label_gpt4']==1]\n",
    "print(len(df_t))\n",
    "for col in ['label_gpt4_prompt_1', 'label_gpt4_prompt_3','label_gpt4_prompt_4']:\n",
    "    entry = {}\n",
    "    entry['cond'] = col\n",
    "    entry['val'] = -round((100 - df_t[col].mean()*100),2)\n",
    "    entry['model'] = 'gpt-4'\n",
    "    entry['task'] = 'misinfo'\n",
    "    print(0.1021*round((df_t[col].mean()*100),2))\n",
    "    list_entries.append(entry)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7051f1",
   "metadata": {},
   "source": [
    "#### Analyses hate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "adc2de1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n",
      "41.67\n",
      "41.67\n",
      "78.33\n"
     ]
    }
   ],
   "source": [
    "df_t = df_h.loc[df_h['label_gpt3.5']==1]\n",
    "print(len(df_t))\n",
    "for col in ['label_gpt3.5_prompt_1', 'label_gpt3.5_prompt_3','label_gpt3.5_prompt_4']:\n",
    "    entry = {}\n",
    "    entry['cond'] = col\n",
    "    entry['val'] = -round((100 - df_t[col].mean()*100),2)\n",
    "    entry['model'] = 'gpt-3.5'\n",
    "    entry['task'] = 'hate'\n",
    "    print(round((100 - df_t[col].mean()*100),2))\n",
    "    list_entries.append(entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3073bff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46\n",
      "43.48\n",
      "39.13\n",
      "82.61\n"
     ]
    }
   ],
   "source": [
    "df_t = df_h.loc[df_h['label_gpt4']==1]\n",
    "print(len(df_t))\n",
    "for col in ['label_gpt4_prompt_1', 'label_gpt4_prompt_3','label_gpt4_prompt_4']:\n",
    "    entry = {}\n",
    "    entry['cond'] = col\n",
    "    entry['val'] = -round((100 - df_t[col].mean()*100),2)\n",
    "    entry['model'] = 'gpt-4'\n",
    "    entry['task'] = 'hate'\n",
    "    print(round((100 - df_t[col].mean()*100),2))\n",
    "    list_entries.append(entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d78f9f2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149\n",
      "4.594352000000001\n",
      "6.383909000000001\n",
      "3.639566\n"
     ]
    }
   ],
   "source": [
    "df_t = df_m.loc[df_m['label_gpt4']==1]\n",
    "print(len(df_t))\n",
    "for col in ['label_gpt4_prompt_1', 'label_gpt4_prompt_3','label_gpt4_prompt_4']:\n",
    "    entry = {}\n",
    "    entry['cond'] = col\n",
    "    entry['val'] = -round((100 - df_t[col].mean()*100),2)\n",
    "    entry['model'] = 'gpt-4'\n",
    "    entry['task'] = 'hate'\n",
    "    print(0.0889*round((df_t[col].mean()*100),2))\n",
    "    list_entries.append(entry)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6aac81d",
   "metadata": {},
   "source": [
    "### Table 8 statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8b212f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = pd.DataFrame(list_entries)[['task','model', 'cond','val']].replace({'label_gpt3.5_prompt_1':'few shot use-mention examples',\n",
    "                                                                    'label_gpt4_prompt_1':'few shot use-mention examples',\n",
    "                                                                   'label_gpt4_prompt_3': 'use mention mitigation',\n",
    "                                                                   'label_gpt3.5_prompt_3': 'use mention mitigation',\n",
    "                                                                   'label_gpt3.5_prompt_4': 'few shot CoT use mention mitigation',\n",
    "                                                                   'label_gpt4_prompt_4': 'few shot CoT use mention mitigation'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fd682fab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task</th>\n",
       "      <th>model</th>\n",
       "      <th>cond</th>\n",
       "      <th>val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>hate</td>\n",
       "      <td>gpt-4</td>\n",
       "      <td>few shot use-mention examples</td>\n",
       "      <td>-43.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>hate</td>\n",
       "      <td>gpt-4</td>\n",
       "      <td>use mention mitigation</td>\n",
       "      <td>-39.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>hate</td>\n",
       "      <td>gpt-4</td>\n",
       "      <td>few shot CoT use mention mitigation</td>\n",
       "      <td>-82.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>misinfo</td>\n",
       "      <td>gpt-4</td>\n",
       "      <td>few shot use-mention examples</td>\n",
       "      <td>-48.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>misinfo</td>\n",
       "      <td>gpt-4</td>\n",
       "      <td>use mention mitigation</td>\n",
       "      <td>-28.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>misinfo</td>\n",
       "      <td>gpt-4</td>\n",
       "      <td>few shot CoT use mention mitigation</td>\n",
       "      <td>-59.06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       task  model                                 cond    val\n",
       "12     hate  gpt-4        few shot use-mention examples -43.48\n",
       "13     hate  gpt-4               use mention mitigation -39.13\n",
       "14     hate  gpt-4  few shot CoT use mention mitigation -82.61\n",
       "3   misinfo  gpt-4        few shot use-mention examples -48.32\n",
       "4   misinfo  gpt-4               use mention mitigation -28.19\n",
       "5   misinfo  gpt-4  few shot CoT use mention mitigation -59.06"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(table.loc[table.model=='gpt-4'].drop_duplicates(subset=['task','model','cond']).sort_values(by = 'task').replace({'gpt-3.5': 'gpt-3.5-turbo (ChatGPT 3.5)'}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0cb0f37",
   "metadata": {},
   "source": [
    "### Table 9 statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3c5e5020",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task</th>\n",
       "      <th>model</th>\n",
       "      <th>cond</th>\n",
       "      <th>val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>hate</td>\n",
       "      <td>gpt-3.5-turbo (ChatGPT 3.5)</td>\n",
       "      <td>few shot use-mention examples</td>\n",
       "      <td>-41.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>hate</td>\n",
       "      <td>gpt-3.5-turbo (ChatGPT 3.5)</td>\n",
       "      <td>use mention mitigation</td>\n",
       "      <td>-41.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>hate</td>\n",
       "      <td>gpt-3.5-turbo (ChatGPT 3.5)</td>\n",
       "      <td>few shot CoT use mention mitigation</td>\n",
       "      <td>-78.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>misinfo</td>\n",
       "      <td>gpt-3.5-turbo (ChatGPT 3.5)</td>\n",
       "      <td>few shot use-mention examples</td>\n",
       "      <td>-58.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>misinfo</td>\n",
       "      <td>gpt-3.5-turbo (ChatGPT 3.5)</td>\n",
       "      <td>use mention mitigation</td>\n",
       "      <td>-46.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>misinfo</td>\n",
       "      <td>gpt-3.5-turbo (ChatGPT 3.5)</td>\n",
       "      <td>few shot CoT use mention mitigation</td>\n",
       "      <td>-73.04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       task                        model                                 cond  \\\n",
       "9      hate  gpt-3.5-turbo (ChatGPT 3.5)        few shot use-mention examples   \n",
       "10     hate  gpt-3.5-turbo (ChatGPT 3.5)               use mention mitigation   \n",
       "11     hate  gpt-3.5-turbo (ChatGPT 3.5)  few shot CoT use mention mitigation   \n",
       "0   misinfo  gpt-3.5-turbo (ChatGPT 3.5)        few shot use-mention examples   \n",
       "1   misinfo  gpt-3.5-turbo (ChatGPT 3.5)               use mention mitigation   \n",
       "2   misinfo  gpt-3.5-turbo (ChatGPT 3.5)  few shot CoT use mention mitigation   \n",
       "\n",
       "      val  \n",
       "9  -41.67  \n",
       "10 -41.67  \n",
       "11 -78.33  \n",
       "0  -58.02  \n",
       "1  -46.76  \n",
       "2  -73.04  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(table.loc[table.model!='gpt-4'].drop_duplicates(subset=['task','model','cond']).sort_values(by = 'task').replace({'gpt-3.5': 'gpt-3.5-turbo (ChatGPT 3.5)'}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
